---
title: >-
  AI Code Generation: Can Free Tools Build Full Apps? A Software Engineer's
  Honest Review
description: Breaking down which AI generated coding tool is good
pubDate: 2025-07-29T19:00:00.000Z
draft: true
authorName: Abdul Rafay
authorAvatar: /new_abdul_rafay.webp
---

I still remember it like yesterday. Fresh out of uni, bright-eyed and bushy-tailed, an intern wading into the world of Machine Learning because, hey, it was *the* trend. Then, one fateful day, my coworkers dropped a bomb: "Have you seen ChatGPT?" My reaction? Let's just say it was less 'Aha!' and more **"Holy Molly!"**

That first encounter with an AI model generating human-like text, and even *code*, was a revelation. Something so simple, yet so profoundly powerful. My brain immediately zeroed in on the code generation—this was a game-changer. Initially, I was doing what any budding engineer might: copy-pasting snippets from a web browser, hoping for the best. And let's be real, the quality often didn't quite match the hype.

### The Copilot Revelation: Speed Over Polish

Then came GitHub Copilot. For a measly ( $10 ) a month, this thing was a wizard. It wasn't about perfect, pristine code in my region—frankly, nobody here bats an eye at clean code as long as the feature ships and looks good. Simple! The velocity increase Copilot gave me was insane. My sprint demos became smoother, my coffee breaks longer. It just *worked* as a developer productivity powerhouse.

### The AI Arms Race: Claude, Cursor, and Beyond

Just when you thought OpenAI had the entire AI coding kingdom cornered, a new challenger appeared: Anthropic's Claude. It was like watching a tech-themed wrestling match, and suddenly, the ring had more contenders. Then Cursor came along, transforming the coding experience even further. Boom! AI coding assistants were everywhere—from your web browser to every IDE imaginable, all designed to supercharge developer workflow.

To this day, my daily workflow is inseparable from Cursor and T3.chat, leveraging Claude's prowess for coding. They’re just *that* good, especially when you're juggling a Master's degree, research, and daily projects in Node, React, Flutter, and Laravel. It’s a wild ride, and every little bit of automation helps!

### The Grand Experiment: Can AI Build a Full App?

Now, with all that background out of the way, we're at the exciting part. We've seen AI generate snippets, complete functions, and even refactor. But the new frontier, the bold claim echoing across the internet, is "full application development." Can these AI tools truly deliver on that promise? I'm curious, perhaps a little skeptical, but mostly just itching to find out.

### The Rules of Engagement (and Why They Matter)

Before we dive into the code-slinging chaos, we need some ground rules. Think of it as my broke-but-determined approach to tech validation.

1. **Free Tier Only:** Because, let's be real, a software engineer trying to master new tech while also pursuing a Master's degree and engaging in research isn't exactly rolling in cash. Plus, most people start here.
2. **Same Prompt, Every Service:** Fairness is key. We're giving each AI the exact same starting line.
3. **One Chance Only, No Do-Overs:** Just like real-world deadlines (minus the existential dread), what you get is what you get. This also reflects how many users interact with these tools casually.

Why these strict rules? Well, aside from my personal financial situation, it’s about leveling the playing field. Many of these incredible tools often run on the same powerful AI models under the hood—be it Claude, AutoGPT, or a flavor of ChatGPT. It’s a true test of their interface, fine-tuning, and direct applicability for everyday developers like me.

### Our Contenders: The AI Gladiators

What are our contenders in this AI coding showdown? We have a couple of intriguing tools that claim to do it all, from scaffolding to full-app generation:

1. **[Lovable](https://lovable.dev/)**
2. **[Bolt.new](https://bolt.new/)**
3. **[Chef by Convex](https://chef.convex.dev/)**
4. **[Orchids](https://www.orchids.app/)**

### The Gauntlet: Our Ultimate AI Prompt

Now, for the main event! The prompt itself needs to be robust enough to push these tools to their limits, demanding a full-stack (even if local-storage-based) web application, not just a bare-bones script. It's got to be better, right? Here's the precise prompt we'll be throwing at each of these services. May the best AI win!

```
Develop a single-page web application for a minimalist to-do list, focused on user experience and maintainability and with Auth as well.

The application should:
1.  **Frontend Framework:** Utilize a modern JavaScript frontend framework (e.g., React, Vue, Svelte, or similar) to construct the UI. The choice should reflect current best practices for component-based development.
2.  **Core Features:**
    *   **Add Tasks:** An input field to add new to-do items. Implement client-side input validation to prevent the creation of empty tasks.
    *   **Manage Completion:** Each to-do item should have a way (e.g., a checkbox or toggle button) to mark it as completed or uncompleted. Completed tasks should have a distinct visual style (e.g., strikethrough or faded text).
    *   **Delete Tasks:** A button or icon next to each task to allow users to delete individual to-do items.
3.  **Data Persistence:** All to-do items must be stored in the browser's Local Storage, ensuring data persists across browser sessions. The application should load existing tasks on startup.
4.  **User Interface:**
    *   **Clean & Responsive Design:** Implement a modern, clean, and responsive design that works well on both desktop and mobile screens. Basic CSS styling is sufficient, but it should be visually appealing.
    *   **Filtering:** Include basic filtering options (e.g., buttons or tabs) to display "All", "Active", or "Completed" tasks.
    *   **Clear Layout:** Organize the UI with a distinct header, an input section for new tasks, and a clear list display for existing tasks.
5.  **Project Structure & Documentation:**
    *   **Complete Project:** Generate a complete and runnable project directory, including all necessary configuration files (e.g., `package.json`).
    *   **Comprehensive README:** Provide a detailed `README.md` file that clearly outlines:
        *   Required dependencies and environment (e.g., Node.js version, browser compatibility).
        *   Step-by-step installation instructions.
        *   Clear commands to run the application locally.
        *   A brief overview of the key components and overall code structure.
    *   **Code Quality:** Ensure the generated code is well-commented, follows reasonable code best practices for the chosen framework, and is easy to understand.
```

Alright, Abdul Rafay, let's refine just that "Lovable" section. We'll make it crisp, clear, and perfectly slot into your existing blog post, handling the more complex prompt you used for it as a specific stress test for *this* tool, leading into your universal prompt for the others.

### **Tool 1: Lovable.dev - The Ambitious Start**

Lovable.dev has been practically living in my ad feeds, so it was naturally the first one I had to put to the test. My initial take? It's got potential, it's *good*, but it definitely feels like there are some rough edges needing polish, or perhaps a full refactor in places.

For Lovable, I decided to push the boundaries right out of the gate, giving it a truly ambitious challenge—a stress test, if you will, to see how far these "full application" claims could truly stretch. My prompt went beyond a simple to-do list, aiming for real-world complexity. I tasked it with:

* **Adding Authentication:** Because what's a modern app without user logins?
* **Database Persistence:** Storing to-do items not just locally, but in a backend database. For this, I specifically chose **Supabase** as the backend.

The **prompting process** itself was quite detailed and involved, guiding me through various configurations, which hinted at the complexity it was trying to handle. In terms of raw speed, Lovable was impressively quick for such a task, taking approximately **3 minutes** to generate what it claimed was a complete application. Not bad for kicking off a new project!![](/BlogImages/loveable_promote.webp)![](/BlogImages/loveable_promote2.webp)![](/BlogImages/loveable_promote3.webp)

As you can see from the process, it’s not all sunshine and rainbows. While the detailed prompting *tried* to cover a lot of ground, the actual output told a different story.

![](/BlogImages/Loveable_5.webp)![](/BlogImages/loveable_UI_4.webp)

The generated UI? It was okay—functional, but nothing to write home about. The real disappointment, though, came when it failed to perform even the most basic "add to-do" task correctly, despite the heavy lifting I asked it to do with authentication and Supabase integration. That's a significant letdown when the fundamental feature falls short.

On a positive note, setting up the Supabase connection for the authentication feature was surprisingly straightforward; it just needed a few button clicks to link it to an existing Supabase project. The *idea* of integrating a backend with such ease is fantastic, even if the execution on the core feature wasn't quite there.

**Lovable.dev Verdict:** While its ambition to tackle auth and external databases with impressive speed is commendable, and the setup for Supabase was intuitive, the failure on basic to-do functionality left a significant gap. It's a powerful *idea*, but the current free-tier execution indicates a need for substantial refinement to deliver on the "full app" promise for complex prompts. This initial deep dive for Lovable truly shaped my approach for the *other* tools, leading me to define the **Universal Prompt** (detailed below) that aims for a strong, robust, yet achievable feature set for consistent comparison.

### Tool 2: Chef by Convex - The Backend Maestro

Next up in our coding crucible is Chef by Convex. Now, I have a soft spot for Convex itself; honestly, it's an amazing product for building robust backend applications. I'm talking production-level stuff, where with the right code and optimization, things really sing. Given my daily use of its API endpoints and services, I wasn't entirely surprised by Chef's performance in certain areas.

When putting Chef to the test with our **Universal Prompt**, its speed was impressive, living up to the snappy performance I expect from Convex's infrastructure. It's incredibly fast, and its real-time preview and websocket capabilities are just what you'd expect from a Convex-powered tool – no surprises there, and definitely a huge plus for rapid iteration.

The **prompting process** with Chef was quite straightforward and workable. It efficiently translated the prompt into a functional application, particularly on the backend.![](/BlogImages/cheif_02.webp)![](/BlogImages/cheif_03.webp)![](/BlogImages/cheif_5.webp)

However, and this is where the *chef* sometimes leaves the presentation a bit simple, the **UI generated** by Chef tends to be quite minimalist. This isn't entirely unexpected, though, as Convex itself shines as a robust database and backend service. Its strength isn't primarily in generating visually stunning frontends, but rather in providing solid, functional backend foundations.

While the UI might be basic, the underlying backend functionality generated by Chef for this "simple" to-do application was robust. It leverages Convex's capabilities well, demonstrating its proficiency where it counts most for data persistence and real-time updates.

**Chef by Convex Verdict:** Chef delivers on its promise of speed and reliable backend functionality, unsurprisingly given Convex's core strengths. If you're looking for an AI tool that nails the data layer and real-time updates, especially with a Convex backend, this is a strong contender. However, don't expect a dazzling frontend out of the box. It’s a tool that excels at plumbing, perhaps leaving the interior decorating to the developer.
